"""Peer Review Assistant example using CrewAI with Ollama."""

import sys
import os
import json
from typing import Dict, Any, Optional

# Add the parent directory to sys.path to allow importing from projects
sys.path.append(os.path.abspath(os.path.join(os.path.dirname(__file__), '..', '..', '..')))

from crewai import Agent, Task, Crew, Process
from projects.utils import UseCase

class PeerReviewAssistantUseCase(UseCase):
    """Peer Review Assistant use case implementation."""
    
    def setup_agents(self):
        """Set up agents for peer review assistance."""
        self.methodology_reviewer = Agent(
            role="Research Methodology Expert",
            goal="Evaluate the research methodology and experimental design",
            backstory="You are a senior researcher with extensive experience in evaluating research "
                     "methodologies across various disciplines. You can identify issues with experimental design, "
                     "sampling methods, statistical approaches, and data collection procedures to ensure "
                     "research is conducted rigorously.",
            allow_delegation=False,
            llm=self.llm,
            tools=self.tools,
            verbose=True
        )
        
        self.content_reviewer = Agent(
            role="Scientific Content Reviewer",
            goal="Assess the clarity, accuracy, and significance of the manuscript content",
            backstory="You are an experienced scientific reviewer who specializes in evaluating the "
                     "quality of scientific content, including literature reviews, results interpretation, "
                     "and theoretical frameworks. You can identify logical gaps, factual inaccuracies, and "
                     "areas where more evidence or explanation is needed.",
            allow_delegation=False,
            llm=self.llm,
            tools=self.tools,
            verbose=True
        )
        
        self.writing_editor = Agent(
            role="Academic Writing Editor",
            goal="Improve the clarity and quality of academic writing",
            backstory="You are a professional editor specializing in academic and scientific writing. "
                      "You have a keen eye for improving structure, flow, readability, and adherence to "
                      "academic writing conventions. You can help authors communicate complex ideas more effectively.",
            allow_delegation=False,
            llm=self.llm,
            tools=self.tools,
            verbose=True
        )
        
        # Add agents to the list
        self.agents = [self.methodology_reviewer, self.content_reviewer, self.writing_editor]
    
    def setup_tasks(self, input_data: Optional[Dict[str, Any]] = None):
        """Set up tasks for peer review assistance.
        
        Args:
            input_data: Optional dictionary containing input data
        """
        # Process input data if provided
        manuscript_title = input_data.get("title", "Advances in Machine Learning for Climate Prediction") if input_data else "Advances in Machine Learning for Climate Prediction"
        
        # Prepare manuscript context if provided
        manuscript_context = ""
        if input_data and "manuscript" in input_data:
            manuscript_context = f"Review the following manuscript:\n\n{input_data['manuscript']}"
        else:
            manuscript_context = "Analyze a hypothetical manuscript on machine learning applications for climate prediction."
        
        # Define tasks
        methodology_review_task = Task(
            description=f"Evaluate the methodology of the manuscript '{manuscript_title}'. {manuscript_context}\n"
                       f"Assess the research design, methods, data collection procedures, analytical techniques, "
                       f"and statistical approaches. Identify any methodological weaknesses, potential biases, "
                       f"or limitations. Suggest specific improvements to strengthen the methodology.",
            expected_output="A comprehensive review of the methodology with specific issues identified and improvements suggested.",
            agent=self.methodology_reviewer,
        )
        
        content_review_task = Task(
            description=f"Evaluate the scientific content and arguments of '{manuscript_title}'. {manuscript_context}\n"
                       f"Assess the accuracy, clarity, and significance of the scientific claims. Evaluate the literature "
                       f"review, results interpretation, and conclusions. Identify any logical flaws, gaps in evidence, "
                       f"or alternative interpretations that should be addressed. Comment on the novelty and potential impact.",
            expected_output="A detailed content review highlighting strengths, weaknesses, and specific recommendations for improvement.",
            agent=self.content_reviewer,
            context=[methodology_review_task]
        )
        
        writing_review_task = Task(
            description=f"Review the writing quality and structure of '{manuscript_title}'. {manuscript_context}\n"
                       f"Evaluate the overall organization, clarity, flow, and readability. Identify issues with "
                       f"paragraph structure, transitions, sentence construction, word choice, and academic style. "
                       f"Provide specific suggestions to improve the writing and ensure it meets high academic standards.",
            expected_output="A detailed writing review with specific examples of issues and constructive suggestions for improvement.",
            agent=self.writing_editor,
            context=[methodology_review_task, content_review_task]
        )
        
        # Add tasks to the list
        self.tasks = [methodology_review_task, content_review_task, writing_review_task]

# Create instance for standalone usage
peer_review_assistant = PeerReviewAssistantUseCase()

def run(input_data: Optional[Dict[str, Any]] = None) -> str:
    """Run the peer review assistant use case.
    
    Args:
        input_data: Optional dictionary containing input data
        
    Returns:
        The result of the peer review process
    """
    # Create a new instance to ensure clean state
    use_case = PeerReviewAssistantUseCase()
    use_case.setup_agents()
    use_case.setup_tasks(input_data)
    use_case.setup_crew(Process.sequential)
    
    # Run the use case
    result = use_case.crew.kickoff()
    return result

if __name__ == "__main__":
    result = run()
    print(result)
