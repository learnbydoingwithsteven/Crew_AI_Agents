"""AI Model Reproducibility example using CrewAI with Ollama."""

import sys
import os
import json
from typing import Dict, Any, Optional

# Add the parent directory to sys.path to allow importing from projects
sys.path.append(os.path.abspath(os.path.join(os.path.dirname(__file__), '..', '..', '..')))

from crewai import Agent, Task, Crew, Process
from projects.utils import UseCase

class AIModelReproducibilityUseCase(UseCase):
    """AI Model Reproducibility use case implementation."""
    
    def setup_agents(self):
        """Set up agents for AI model reproducibility."""
        self.code_analyst = Agent(
            role="ML Code Analyst",
            goal="Analyze AI model code for reproducibility factors",
            backstory="You are a machine learning engineer specialized in code quality and reproducibility. "
                     "You have extensive experience analyzing ML codebases to identify factors affecting "
                     "reproducibility such as random seeds, data preprocessing, hyperparameters, "
                     "and environment dependencies. You can recommend best practices for reproducible AI.",
            allow_delegation=False,
            llm=self.llm,
            tools=self.tools,
            verbose=True
        )
        
        self.data_scientist = Agent(
            role="Research Data Scientist",
            goal="Evaluate data handling practices and experimental design",
            backstory="You are a research data scientist with expertise in experimental design and "
                     "data management for reproducible AI. You understand how data splits, preprocessing "
                     "pipelines, and evaluation methodologies impact reproducibility. You can identify "
                     "issues in experimental protocols that might lead to non-reproducible results.",
            allow_delegation=False,
            llm=self.llm,
            tools=self.tools,
            verbose=True
        )
        
        self.reproducibility_engineer = Agent(
            role="AI Reproducibility Engineer",
            goal="Develop comprehensive reproducibility protocols",
            backstory="You are a specialized engineer focused on ensuring AI research reproducibility. "
                      "You have developed standards and practices for reproducible AI research across "
                      "different domains. You understand containerization, dependency management, "
                      "version control best practices, and documentation requirements for reproducibility.",
            allow_delegation=False,
            llm=self.llm,
            tools=self.tools,
            verbose=True
        )
        
        # Add agents to the list
        self.agents = [self.code_analyst, self.data_scientist, self.reproducibility_engineer]
    
    def setup_tasks(self, input_data: Optional[Dict[str, Any]] = None):
        """Set up tasks for AI model reproducibility.
        
        Args:
            input_data: Optional dictionary containing input data
        """
        # Process input data if provided
        model_type = input_data.get("query", "Transformer-based natural language generation model") if input_data else "Transformer-based natural language generation model"
        
        # Prepare model context if provided
        model_context = ""
        if input_data and "model_details" in input_data:
            model_context = f"Use the following model details for analysis: {json.dumps(input_data['model_details'])}"
        
        # Define tasks
        code_analysis_task = Task(
            description=f"Analyze the code implementation of the '{model_type}' for reproducibility factors. {model_context}\n"
                       f"Evaluate the codebase for reproducibility issues including random seed handling, hardware "
                       f"dependencies, non-deterministic operations, and hyperparameter management. Identify code-level "
                       f"factors that could lead to reproducibility problems. Provide specific recommendations for "
                       f"improving code reproducibility.",
            expected_output="A detailed code analysis report with identified reproducibility issues and specific recommendations.",
            agent=self.code_analyst,
        )
        
        data_evaluation_task = Task(
            description=f"Evaluate the data handling practices and experimental design for the '{model_type}'. "
                       f"Assess how data is processed, split, and used in training and evaluation. Analyze the "
                       f"experimental methodology for issues that might affect reproducibility, such as data leakage, "
                       f"inconsistent preprocessing, or problematic evaluation metrics. Suggest improvements to "
                       f"ensure data-related reproducibility.",
            expected_output="A comprehensive evaluation of data practices and experimental design with recommendations.",
            agent=self.data_scientist,
            context=[code_analysis_task]
        )
        
        reproducibility_protocol_task = Task(
            description=f"Develop a comprehensive reproducibility protocol for the '{model_type}'. "
                      f"Based on the code and data analyses, create a detailed protocol covering environment "
                      f"setup, code execution, data handling, and result validation. Include specific steps for "
                      f"containerization, dependency management, configuration tracking, and documentation. "
                      f"Provide a checklist for researchers to verify reproducibility of the model.",
            expected_output="A complete reproducibility protocol with implementation steps and verification checklist.",
            agent=self.reproducibility_engineer,
            context=[code_analysis_task, data_evaluation_task]
        )
        
        # Add tasks to the list
        self.tasks = [code_analysis_task, data_evaluation_task, reproducibility_protocol_task]

# Create instance for standalone usage
ai_model_reproducibility = AIModelReproducibilityUseCase()

def run(input_data: Optional[Dict[str, Any]] = None) -> str:
    """Run the AI model reproducibility use case.
    
    Args:
        input_data: Optional dictionary containing input data
        
    Returns:
        The result of the AI model reproducibility process
    """
    # Create a new instance to ensure clean state
    use_case = AIModelReproducibilityUseCase()
    use_case.setup_agents()
    use_case.setup_tasks(input_data)
    use_case.setup_crew(Process.sequential)
    
    # Run the use case
    result = use_case.crew.kickoff()
    return result

if __name__ == "__main__":
    result = run()
    print(result)
